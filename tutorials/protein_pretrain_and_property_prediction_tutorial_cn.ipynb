{
 "cells": [
  {
   "source": [
    "# 蛋白质预训练和性质预测\n",
    "\n",
    "在这份教程中，我们将介绍如何构建一个序列模型来进行蛋白质性质预测。具体来说，我们将展示如何对模型进行预训练并针对下游任务进行微调。\n",
    "\n",
    "近年来，随着测序技术的发展，蛋白质序列数据库的规模显著扩大。然而，必须通过湿实验才能够获得的有标注蛋白序列的成本仍然很高。此外，由于标记样本数量不足，模型有很高的概率过拟合数据。借鉴自然语言处理（NLP）的思想，通过自监督学习可以在大量无标注的蛋白序列上进行预训练。这样，我们就可以从蛋白质序列中提取有用的生物信息，并将其迁移到其他有标注的任务中，使这些任务的训练速度更快和更稳定地收敛。本教程的内容参考了 TAPE 的工作，提供了 Transformer、LSTM 和 ResNet 的模型实现。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 第一部分：预训练/训练"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../apps/pretrained_protein/tape')\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载相关工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from utils import *\n",
    "\n",
    "paddle.enable_static() # paddle 版本 >= 2.0.0rc\n",
    "\n",
    "is_distributed = False\n",
    "use_cuda = False\n",
    "thread_num = 8\n",
    "\n",
    "# Setup the execution-related parameters according to the training modes.\n",
    "exe_params = default_exe_params(is_distributed=is_distributed, use_cuda=use_cuda, thread_num=thread_num)\n",
    "exe = exe_params['exe']\n",
    "trainer_num = exe_params['trainer_num']\n",
    "trainer_id = exe_params['trainer_id']\n",
    "gpu_id = exe_params['gpu_id']\n",
    "dist_strategy = exe_params['dist_strategy'] \n",
    "places = exe_params['places']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型配置\n",
    "\n",
    "模型的配置如下面的 `model_config` 所示。\n",
    "- 任务相关的配置\n",
    "    - \"task\"：训练任务的类型。可选的类型包括：\n",
    "        - \"pretrain\"：使用自监督学习的方法的预训练任务，如数据集 `TAPE`。\n",
    "        - \"classification\"：分类任务，如数据集 `Remote Homology`。\n",
    "        - \"regression\"：回归任务，如数据集 `Fluroscence` 和 `Stability`。\n",
    "        - \"seq_classification\"：序列分类任务，如数据集 `Secondary Structure`。\n",
    "    - \"class_num\"：任务 `classification` 和 `seq_classification` 中类别的数量。\n",
    "    - \"label_name\"：数据集中的标签名。\n",
    "- 模型相关的配置\n",
    "    - \"model_type\"：模型的类型。 对每个模型，我们需要指定相应的模型超参数。下面是我们支持的模型：\n",
    "        - \"transformer\"\n",
    "            - \"hidden_size\"\n",
    "            - \"layer_num\"\n",
    "            - \"head_num\"\n",
    "        - \"lstm\"\n",
    "            - \"hidden_size\"\n",
    "            - \"layer_num\"\n",
    "        - \"resnet\"\n",
    "            - \"hidden_size\"\n",
    "            - \"layer_num\"\n",
    "            - \"filter_size\"\n",
    "- 其他配置（更多细节请查阅代码）\n",
    "    - \"dropout_rate\"\n",
    "    - \"weight_decay\"\n",
    "    \n",
    "下面的 `model_config` 是模型配置的一个示例，任务的名称是 `secondary_structure`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_config = \\\n",
    "{\n",
    "    \"model_name\": \"secondary_structure\",\n",
    "\n",
    "    \"task\": \"seq_classification\",\n",
    "    \"class_num\": 3,\n",
    "    \"label_name\": \"labels3\",\n",
    "\n",
    "    \"model_type\": \"lstm\",\n",
    "    \"hidden_size\": 512,\n",
    "    \"layer_num\": 3,\n",
    "\n",
    "    \"comment\": \"The following hyper-parameters are optional.\",\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"weight_decay\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型定义\n",
    "\n",
    "通常情况下可以使用 Paddle 中提供的 `Program` 和 `Executor` 来构建静态图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tape_model import TAPEModel # More details of the network structure are shown in tape_model.py.\n",
    "from data_gen import setup_data_loader\n",
    "from pahelix.utils.paddle_utils import load_partial_params\n",
    "\n",
    "model = TAPEModel(model_config=model_config)\n",
    "\n",
    "lr = 0.0001 # learning rate\n",
    "batch_size = 32 # batch size\n",
    "train_data = './demos/secondary_structure_toy_data'\n",
    "\n",
    "# prepare train_program\n",
    "train_program = fluid.Program()\n",
    "train_startup = fluid.Program()\n",
    "with fluid.program_guard(train_program, train_startup):\n",
    "    with fluid.unique_name.guard():\n",
    "        model.forward(False)\n",
    "        model.cal_loss()\n",
    "\n",
    "        # setup the optimizer\n",
    "        optimizer = default_optimizer(lr=lr, warmup_steps=0, max_grad_norm=0.1)\n",
    "        setup_optimizer(optimizer, model, use_cuda, is_distributed)\n",
    "        optimizer.minimize(model.loss)\n",
    "        \n",
    "        # setup the data loader, which provides the training data\n",
    "        train_data_loader = setup_data_loader(\n",
    "                model.input_list,\n",
    "                model_config,\n",
    "                train_data,\n",
    "                trainer_id,\n",
    "                trainer_num,\n",
    "                places,\n",
    "                batch_size)\n",
    "        exe.run(train_startup)\n",
    "\n",
    "# init_model = \"./pretrained_model\" # we could load the pre-trained model\n",
    "# load_partial_params(exe, init_model, test_program) # load the init_model\n",
    "\n",
    "save_program = train_program\n",
    "if not is_distributed:\n",
    "    save_program = train_program\n",
    "    train_program = fluid.compiler.CompiledProgram(train_program).with_data_parallel(loss_name=model.loss.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tExample: 78011\n",
      "\tAccuracy: 0.309482\n",
      "\tExample: 144800\n",
      "\tAccuracy: 0.388985\n",
      "Epoch 1\n",
      "\tExample: 78011\n",
      "\tAccuracy: 0.522811\n",
      "\tExample: 144800\n",
      "\tAccuracy: 0.515760\n"
     ]
    }
   ],
   "source": [
    "task = model_config['task']\n",
    "train_metric = get_metric(task) # evaluation metric\n",
    "train_fetch_list = model.get_fetch_list() # information needed for prediction and evaluation\n",
    "model_dir = \"./model\" # the directory to save the model\n",
    "\n",
    "for epoch_id in range(2):\n",
    "    print('Epoch %d' % epoch_id)\n",
    "    train_metric.clear() # cleanup the evaluation metric\n",
    "    for data in train_data_loader():\n",
    "        results = exe.run(\n",
    "                program=train_program,\n",
    "                feed=data,\n",
    "                fetch_list=train_fetch_list,\n",
    "                return_numpy=False)\n",
    "        update_metric(task, train_metric, results) # update the evaluation metric\n",
    "        train_metric.show() # show the results of the metrics\n",
    "    if trainer_id == 0:\n",
    "        fluid.io.save_params(exe, '%s/epoch%d' % (model_dir, epoch_id), save_program) # save model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分：模型推断\n",
    "\n",
    "在这一部分，我们将简要介绍如何使用训练后的模型在给定的氨基酸序列上进行推断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load parameters from ./model/epoch0.\n",
      "[[0.33362675 0.3326527  0.33372056]\n",
      " [0.33355793 0.3325862  0.33385593]\n",
      " [0.33341178 0.3326046  0.33398363]\n",
      " ...\n",
      " [0.33260044 0.331602   0.33579758]\n",
      " [0.33269978 0.33188707 0.33541316]\n",
      " [0.33314735 0.3324862  0.33436644]]\n"
     ]
    }
   ],
   "source": [
    "from pahelix.utils.paddle_utils import load_partial_params\n",
    "from pahelix.utils.protein_tools import ProteinTokenizer\n",
    "from data_gen import gen_batch_data\n",
    "\n",
    "test_data = './demos/secondary_structure_toy_data'\n",
    "\n",
    "# prepare test_program\n",
    "test_program = fluid.Program()\n",
    "test_startup = fluid.Program()\n",
    "with fluid.program_guard(test_program, test_startup):\n",
    "    with fluid.unique_name.guard():\n",
    "        model.forward(True)\n",
    "        test_data_loader = setup_data_loader(\n",
    "                model.input_list,\n",
    "                model_config,\n",
    "                test_data,\n",
    "                trainer_id,\n",
    "                trainer_num,\n",
    "                places,\n",
    "                batch_size)\n",
    "        exe.run(test_startup)\n",
    "test_metric = get_metric(task)\n",
    "\n",
    "init_model = \"./model/epoch0\" # the path of initialized model\n",
    "load_partial_params(exe, init_model, test_program) # load the init_model\n",
    "\n",
    "tokenizer = ProteinTokenizer() \n",
    "test_fetch_list = model.get_fetch_list(is_inference=True)\n",
    "\n",
    "if use_cuda:\n",
    "    place = fluid.CUDAPlace(gpu_id)\n",
    "else:\n",
    "    place = fluid.CPUPlace()\n",
    "\n",
    "examples = [\n",
    "    'MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHGKKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTPAVHASLDKFLASVSTVLTSKYR',\n",
    "    'CCCACAGACTCAGAGAGAACCCACCATGGTGCTGTCTCCTGACGACAAGACCAACGTCAAGGCCGCCTGGGGTAAGGTCGGCGCGCACGCTGGCGAGTATGGTGCGGAGGCCCTGGAGAGGATGTTCCTGTCCTTCCCCACCACCAAGACCTACTTCCCGCACTTCGACCTGAGCCACGGCTCTGCCCAGGTTAAGGGCCACGGCAAGAAGGTGGCCGACGCGCTGACCAACGCCGTGGCGCACGTGGACGACATGCCCAACGCGCTGTCCGCCCTGAGCGACCTGCACGCGCACAAGCTTCGGGTGGACCCGGTCAACTTCAAGCTCCTAAGCCACTGCCTGCTGGTGACCCTGGCCGCCCACCTCCCCGCCGAGTTCACCCCTGCGGTGCACGCCTCCCTGGACAAGTTCCTGGCTTCTGTGAGCACCGTGCTGACCTCCAAATACCGTTAAGCTGGAGCCTCGGTGGCCATGCTTCTTGCCCCTTTGG',\n",
    "]\n",
    "inputs = gen_batch_data(examples, tokenizer, place) # data process: 1.change amino acid sequence to token ids and generate a batch\n",
    "results = exe.run(\n",
    "    program=test_program,\n",
    "    feed=inputs,\n",
    "    fetch_list=test_fetch_list,\n",
    "    return_numpy=False)\n",
    "pred = np.array(results[0])\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('pahelix': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5f2af7e1664b1b431746bcf7b354b550c2de8600c44162302fbdafd8f3c94797"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}